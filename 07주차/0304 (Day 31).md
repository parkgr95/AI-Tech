- 스페셜 미션
  - ai - 클로버 대회


- 합동 멘토링
  - nlp 동향
  - cv 동향
    - model 성능 향상
      - ViT
    - Generative Model
      - Dali
  - Diffusion Model
    - Generative Model의 중요성 3가지
      - 그림이 만들어지는데 걸리는 시간
      - 만들어진 그림의 다양성
      - 만들어진 그림의 선명도
  - text to image

- 회고
박기련_T3082 

최고 점수: Best F1 0.7131 

나는 내 학습목표를 달성하기 위해 무엇을 어떻게 했는가? 

저희 팀은 이번 대회의 목표를 순위가 아닌 학습에 두었습니다. 그래서 코드를 공유하며 점수를 높이기보단 각자 코드를 만들어가며 자신이 어떤 방법을 사용했는지, 어떤 식으로 했더니 성능이 올라갔는지를 공유해가며 진행했습니다.  

저도 이전까진 딥러닝을 거의 접하지 못했던 터라 성적에 연연하지 않고 어떻게 딥러닝 학습을 해야하는지 감을 잡고 방법을 배우는데 초점을 두었습니다. 그래서 저는 이번 대회에서 지금까지 배웠던 모델들을 사용해보고 data augmentation, 하이퍼 파라미터 튜닝 위주로 진행했습니다. 

나는 어떤 방식으로 모델을 개선했는가? 

모델 

가장 먼저 모델을 바꿔봤습니다. 처음엔 resnet18을 사용해봤고, 그 다음 efficientnet_b4, b6을 사용해봤습니다. Efficientnet 모델들의 결과는 그렇게 차이나지 않음을 확인하고, 모델보단 학습 전략에 초점을 맞춰야겠다고 느꼈습니다. 단일 모델론 b6, kfold를 사용할 땐 b4 모델을 고정적으로 사용했습니다. 

Data Augmentation 

Albumentation 라이브러리를 사용했습니다. Resize보단 Centercrop으로 데이터들의 인물부분만 학습하게 해주었습니다. 또한 OneOf를 사용해 제가 설정한 확률 대로 좌우반전, 회전, noise등을 넣어 데이터들을 변형시켜주었습니다. 

Multi sample dropout을 적용해서 학습을 진행했습니다. 

Loss 

F1Loss : 성능이 가장 좋아 사용했습니다. 

Optimizer & Scheduler 

Adam :기존의 SGD를 사용했을때보다 Adam을 사용할 때 성능이 더 높아서 사용했습니다. 

Reducelronplateau 함수를 사용해 학습률의 변화가 없을 경우 learning rate를 변화시켜주었습니다. 

데이터 불균형 

WeightedRanddomSampler : 데이터 불균형을 해결하기 위한 oversampling으로 사용했습니다. 가장 큰 성능 상승을 올려주었습니다. 

잘못된 라벨링 

토론글에 공유된 잘못되어 보이는 경우를 manual하게 고쳐줬습니다. 

Ensemble 

Stratified K-fold (K=5)로 학습하고, Soft voting을 사용했습니다. 

내가 한 행동의 결과로 어떤 지점을 달성하고, 어떠한 깨달음을 얻었는가? 

여러 기법을 사용해보며 최대 F1 Score 0.7131을 달성할 수 있었습니다. 균형적인 데이터일 경우가 많지 않으므로 불균형을 잡아주는 것이 중요하고, 내가 원하는 성능의 비슷한 모델은 있어도 똑같은 모델은 없기에 데이터를 고려하며 바꿔주는 것이 중요하다를 알게되었습니다. 

전과 비교해서, 내가 새롭게 시도한 변화는 무엇이고, 어떤 효과가 있었는가? 

단순히 모델, 하이퍼 파라미터 튜닝이 아닌 여러가지 기법 (oversampling, scheduler, enseomble) 을 적용시켜봤습니다. 결과적으로 조금이라고 f1 score 상승을 이뤄낼 수 있었습니다. 

마주한 한계는 무엇이며, 아쉬웠던 점은 무엇인가? 

먼저 나이, 성별, 마스크 마다 각각을 고려하지 않은 점이 가장 f1 점수가 낮았던 이유였던 것 같습니다. 즉 이번 프로젝트에서 저는 가장 중요한 데이터를 고려하지 않았던 것입니다. 먼저 데이터의 특징을 잘 파악하지 못한 게 가장 큰 아쉬움으로 다가왔습니다. 

또한 상황을 잘 통제하지 못했던 점도 아쉬움으로 다가왔습니다. train, val마다 transformer를 분리하지 않고 실험을 진행했습니다. 기본적으로 세세하게 통제하지 못한 게 아쉬웠습니다. 

마지막으로 더 많은 기법들을 사용해보지 못한게 아쉬웠습니다. Psudo labeling, TTA 등, 적용을 못시켜본게 아쉬웠습니다. 

한계/교훈을 바탕으로 다음 프로젝트에서 스스로 새롭게 시도해볼 것은 무엇일까? 

EDA를 가장 열심히 해보기 

VIT 모델, swin transformer 등 좀 더 다양한 모델을 사용해보기 

Cascade learning으로 진행해보기 

 
