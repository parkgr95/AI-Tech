# 1. 1월18일 (Day 2) 학습 정리
### (AI Math 1강) 벡터가 뭐에요?

- 벡터란?
  - 숫자를 원소로 가지는 리스트(list) or 배열(array)
  - 공간에서 한 점을 나타낸다.
  - 원점으로부터 상대적 위치를 표현한다.
  - 벡터에 숫자를 곱해주면 길이만 변한다. 이때 스칼라곱이라 부른다.
  - 벡터끼리 같은 모양을 가지면 덧셈, 뺄셈, 성분곱(Hadamard product)을 계산할 수 있다.
- 벡터의 덧셈
  - 두 벡터의 덧셈은 다른 벡터로부터의 상대적 위치이동을 표현한다.
  -  뺄셈은?
    - 뺄셈은 방향을 뒤집은 덧셈이다.
- 백터의 노름(norm)이란?
  - 원점에서부터의 거리를 말한다.
  - L1-노름은 각 성분의 변화량의 절대값을 모두 더한다.
  - L2-노름은 피타고라스 정리를 이용해 유클리드 거리를 계산한다.
- 다른 노름을 소개하는 이유는?
  - 노름의 종류에 따라 기하학적 성질이 달라지기 때문.
  - 머신러닝에선 각 성질들이 필요할 때가 있으므로 둘 다 사용한다.
- 두 벡터 사이의 거리 구하기
  - L1, L2-노름을 이용해 두 벡터 사이의 거리를 계산할 수 있다.
  - 두 벡터 사이의 거리를 계산할 때는 벡터의 뺄셈을 이용한다.
- 두 벡터 사이의 각도 구하기
  - 제 2 코사인 법칙에 의해 두 벡터 사이의 각도를 계산할 수 있다.
- 내적이란?
  - 내적은 정사영(orthogonal projection)된 벡터의 길이와 관련 있다.
  - Proj(x)의 길이는 코사인법칙에 의해 ∥x∥cosθ가 된다.
  - 내적은 정사영의 길이를 벡터 y 의 길이 ∥y∥만큼 조정한 값이다.
  - 내적은 두 벡터의 유사도(similarity)를 측정하는데 쓸 수 있다.

### (AI Math 2강) 행렬이 뭐에요?

- 행렬이란?

  - 벡터를 원소로 가는 2차원 배열
  - 행(row)과 열(colunmn)이라는 인덱스(index)를 가진다.
  - 행렬의 특정 행(열)을 고정하면 행(열)벡터라 부른다.
  - 벡터가 공간에서 한 점을 의미한다면 행렬은 여러 점들을 나타낸다.
  - 행렬의 행벡터 xi는 i번째 데이터를 의미한다.
  - 행렬의 xij는 i번째 데이터의 j번째 변수의 값을 말한다.
  - 행렬은 벡터공간에서 사용되는 연산자(operator)로 이해한다.
  - 행렬곱을 통해 벡터를 다른 차원의 공간으로 보낼 수 있다.
  - 행렬곱을 통해 패턴을 추출할 수 있고 데이터를 합축할 수도 있다.

- 행렬의 덧셈, 뺼셈, 성분곱, 스칼라곱

  - 같은 모양을 가진 행렬끼리 덧셈, 뺄셈, 성분곱, 스칼라곱을 계산할 수 있다.

- 행렬 곱셈(Matrix Multiplication)

  - 행렬곱셈은 i번째 행벡터와 j번째 열벡터 사이의 내적을 성분으로 가지는 행렬을 계산한다.
  - numpy에선 @연산을 사용

- 행렬도 내적이 있는가?

  - numpy의 np.inner는 i번째 행벡터와 j번째 행벡터 사이의 내적을 성분으로 가지는 행렬을 계산합니다. 수학의 내적과는 다르니 주의!

- 역행렬(Inverse Matrix)

  - 어떤 행렬 A 의 연산을 거꾸로 되돌리는 행렬을 역행렬이라 부르고 A−1 라 표기한다.

  - 역행렬은 행과 열 숫자가 같고 행렬식(determinant)이 0이 아닌 경우에만 계산할 수 있다.

  - 만일 역행렬을 계산할 수 없다면 유사역행렬(pseudo-inverse) 또는 무어-펜로즈(Moore-Penrose) 역행렬 A+을 이용한다.

    ![image-20220122174405413](https://user-images.githubusercontent.com/62732145/150639676-57e4b2c2-c7a1-4175-a53b-6ad5397aa8db.png)

- 응용
  - np.linalg.pinv를 이용하면 연립방정식의 해를 구할 수 있다.
  - np.linalg.pinv를 이용하면 데이터를 선형모델(linear model)로 해석하는 선형회귀식을 찾을 수 있다.
    - 이는 sklearn의 LinearRegression 과 같은 결과를 가져올 수 있다.
    - 단 y전편(intercept) 항을 직접 추가해야 같은 결과를 가져온다. 이것이 bias 결합!
    - 결합하는 이유? 회귀분석모형 수식을 간단하게 만들기 위해

### (AI Math 3강)  경사하강법 - 순한맛

- 미분(differentiation)이란? 

  - 변수의 움직임에 따른 **함수값의 변화를 측정하기 위한 도구**로 최적화에서 제일 많이 사용하는 기법이다.

  - 미분의 정의 - 변화율의 극한(limit)

    ![CodeCogsEqn](https://user-images.githubusercontent.com/62732145/149924638-ab8cce08-5aaf-4dc0-a359-953396fe3922.png) 
  
  - 미분은 함수 ![1](https://user-images.githubusercontent.com/62732145/149925152-63f25886-36a3-4f25-97fe-06582b6cf349.png)의 주어진 점 ![2](https://user-images.githubusercontent.com/62732145/149925236-5324b6d7-7417-4354-af36-b7e178cb3446.png)에서의 **접선의 기울기**를 구하는 것.

  - 미분을 어디에 쓸까? 한 점에서 접선의 기울기를 알면 어느 방향으로 점을 움직여야 함수값이 증가하는지 혹은 감소하는지를 알 수 있다.

    - 증가시키고 싶다면 미분값을 더하고, 감소시키고 싶으면 미분값을 뺀다.

  - **경사상승법(gradient ascent)**

    ![경사상승법](https://user-images.githubusercontent.com/62732145/149925322-1c5f88c0-200a-48d4-bae7-44dc3feb2dba.png)  
  :  미분값을 더하면 경사상승법 이라 하며 함수의 극대값의 위치를 구할 때 사용한다. 목적함수를 최대화할 때 사용한다.

  - **경사하강법(gradient descent)**

    ![경사하강법](https://user-images.githubusercontent.com/62732145/149925339-c7148374-f11f-41aa-aa9f-5d138f9d5682.png)  
  : 미분값을 빼면 경사하강법 이라 하며 함수의 극소값의 위치를 구할 때 사용한다. 목적함수를 최소화할 때 사용한다.
  
  - 경사상승/경사하강 방법은 극값에 도달하면 움직임을 멈춘다.

- 경사하강법 알고리즘
  
  ![image-20220122202136132](https://user-images.githubusercontent.com/62732145/150639763-c34644fb-41c0-4213-acbb-a26a7bdfcc83.png)

- 변수가 벡터라면? 벡터가 입력인 다변수 함수의 경우 **편미분(partial differentiation)**을 사용한다.

  ![CodeCogsEqn (1)](https://user-images.githubusercontent.com/62732145/149926052-c5496e4f-c251-4807-8ff5-00c9541abd3f.png)

- 각 변수 별로 편미분을 계산한 **그레디언트(gradient) 벡터**를 이용하여 경사하강/경사상승법에 사용할 수 있다.  

  ![CodeCogsEqn (2)](https://user-images.githubusercontent.com/62732145/149926065-6d15abda-c31e-4988-87d8-3597b741977c.png)

### (AI Math 4강)  경사하강법 - 매운맛

- 경사하강법으로 선형회귀 계수 구하기.

  - 선형모델의 경우 위와 같이 역행렬을 이용해서 회귀분석이 가능하다.

  - 역행렬을 이용하지 말고 경사하강법을 이용해 적절한 선형모델을 찾아보자.

  - 선형회귀의 목적식은 ![3](https://user-images.githubusercontent.com/62732145/149925433-fc77b42f-f86f-400f-8768-39397deb53fd.png)이고 이를 최소화하는 ![4](https://user-images.githubusercontent.com/62732145/149925463-115f4dbc-8dfb-4362-b280-94de3b2848a8.png)를 찾아야 하므로 다음과 같은 그레디언트 벡터를 구해야 한다.

    ![image](https://user-images.githubusercontent.com/62732145/150639855-64b70b34-faf8-4f0d-a35c-8f364cf42a8e.png)

    - 이때의 L2-norm을 계산할 때 한 개의 점에 대한 L2-norm을 계산하는 것이 아니라 n개의 데이터에 대한 L2-norm을 계산하는 것이기 때문에 i=1~n까지의 값을 모두 더해준 뒤 n개로 나누어 평균값을 사용하게 된다.
    
    - n으로 나누지 않으면, 데이터가 많아서 오차의 합이 커지는지 실제로 오차가 커서 오차의 합이 커지는지를 모르기 때문에 평균을 구한다. 
  
    ![image](https://user-images.githubusercontent.com/62732145/150639875-cd5fbccf-cd03-4945-bbf8-371357e7434e.png)


  - 이제 목적식을 최소화하는 ![4](https://user-images.githubusercontent.com/62732145/149925628-a94fa607-6249-464f-b4fe-66b1410eb8b4.png)를 구하는 경사하강법 알고리즘은 다음과 같다.  

    ![image](https://user-images.githubusercontent.com/62732145/150639888-85387ecd-dcf3-47b8-abf3-9a6010cecafa.png)

  
- **확률적 경사하강법(stochastic gradient descent)** 이란?
  
  - 모든 데이터를 사용해서 업데이트하는 대신 데이터 한개 또는 일부를 활용하여 업데이트하는 기법이다.

  - 볼록이 아닌(non-convex) 목적식은 SGD를 통해 최적화할 수 있다.

    ![image-20220122205717796](https://user-images.githubusercontent.com/62732145/150639933-f30e6b3b-78e2-45e7-a295-7011e9f4b374.png)

    - SGD라고 해서 만능은 아니지만 딥러닝의 경우 SGD가 경사하강법보다 실증적으로 더 낫다고 검증되었다.

  - SGD는 데이터의 일부를 가지고 패러미터를 업데이트하기 때문에 연산자원을 좀 더 효율적으로 활용하는데 도움이 된다.
  
    - 전체데이터 *(X, y)* 를쓰지않고미니배치 *(X(b), y(b))를 써서 업데이트 하므로 연산량이 b/n로 감소한다.

- 확률적 경사하강법의 원리: 미니배치 연산

  - 경사하강법은 전체데이터 𝒟=(X, y)를 가지고 목적식의 그레디언트 벡터인 ∇θL(𝒟,θ)를 계산한다.
 
  - SGD는 미니배치 𝒟(b) = (X(b), y(b))⊂𝒟를 가지고 그레디언트 벡터를 계산한다.

    ![미니배치 연산](https://user-images.githubusercontent.com/62732145/149925772-95742458-e906-408c-a897-c7e17dd5c1d1.png)

- SGD vs 미니배치

  - SGD는 랜덤하게 추출한 일부 데이터를 사용하기에, 학습 중간 과정에서 결과의 진폭이 크고 불안정하지만 속도가 매우 빠르다.

    ![img](https://t1.daumcdn.net/cfile/tistory/996AFC3C5B0CF0C901)

    (출처: https://twinw.tistory.com/247)

    ![img](https://blog.kakaocdn.net/dn/SRACX/btqAkxQ8pkf/clRtX6wjdmVfpU9Z9V1rB1/img.png)

    (출처: https://nonmeyet.tistory.com/entry/Batch-MiniBatch-Stochastic-%EC%A0%95%EC%9D%98%EC%99%80-%EC%84%A4%EB%AA%85-%EB%B0%8F-%EC%98%88%EC%8B%9C)

  - 미니배치는 전체 학습데이터를 배치 사이즈로 나누어서 순차적으로 진행하기에, SGD 보다 낮은 오차율을 가지고 Batch 보다 빠르다. 

### (Python 2-3강) Conditionals and Loops

- 조건문이란?

  - 조건에 따라 특정한 동작을 하게하는 명령어
  - 조건문은 조건을 나타내는 기준과 실행해야 할 명령으로 구성됨
  - 조건의 참, 거짓에 따라 실행해야 할 명령이 수행되거나 수행되지 않음
  - 파이썬은 조건문으로 if , else , elif 등의 예약어를 사용함

- if-else문 문법

  ![image-20220122211608103](https://user-images.githubusercontent.com/62732145/150640019-408dc9a9-4d05-45b6-b238-70e6e0060055.png)

  - 가장 기본적인 조건문으로 조건에 따른 명령을 실행
  - 수행할 명령문이 한 줄이면 붙여쓰기 가능

- 조건 판단 방법

  - if 다음에 조건을 표기하여 참 또는 거짓을 판단함

  - 참/거짓의 구분을 위해서는 비교 연산자를 활용

    | **비교 연산자** | **비교 상태** |            **설명**            |
    | :-------------: | :-----------: | :----------------------------: |
    |      x < y      |  ~보다 작음   |     x과 y보다 작은지 검사      |
    |      x > y      |   ~ 보다 큼   |      x과 y보다 큰지 검사       |
    |     x == y      |     같음      |      x와 y과 같은지 검사       |
    |     x is y      |     같음      | 값과 메모리 주소가 같은지 검사 |
    |     x != y      |   같지 않음   |      x와 y과 다른지 검사       |
    |   x is not y    |   같지 않음   | 값과 메모리 주소가 다른지 검사 |
    |     x >= y      |  크거나 같음  |    x과 y보다 이상인지 검사     |
    |     x <= y      |  작거나 같음  |    x과 y보다 이하인지 검사     |

    - 숫자형의 경우는 수학에서의 참/거짓과 동일
    - 존재하면 참 없으면 거짓

- 논리 키워드 사용: and or not

  - 조건문을 표현할 때 집합의 논리 키워드를 함께 사용하여 참과 거짓을 판단하기도 함

- 삼항 연산자(Ternary operators)
  - 조건문을 사용하여 참일 경우와 거짓일 경우의 결과를 한줄에 표현
- 반복문이란?
  - 정해진 동작을 반복적으로 수행하게 하는 명령문
  - 반복문은 반복 시작 조건, 종료 조건, 수행 명령으로 구성됨
  - 반복문 역시 반복 구문은 들여쓰기와 블록으로 구분됨
  - 파이썬은 반복문으로 for, while 등의 명령 키워드를 사용함
  - 반복문 변수명
    - 임시적인 반복 변수는 대부분 i, j, k로 정함
    - 반복문의 대부분은 0부터 반복을 시작
- 반복의 제어
  - break - 특정 조건에서 반복 종료.
  - continue - 특정 조건에서 남은 반복 명령 생략
  - else
    - 반복 조건이 만족하지 않은 경우 반복 종료 시 1회 수행.
    -  break로 종료된 반복문은 else block이 수행되지 않음
- 디버깅 (debugging)
  - 코드의 오류를 발견하여 수정하는 과정
  - 오류의 원인을 알고 해결책을 찾아야 함
  - 문법적 에러를 찾기 위한 에러 메시지 분석
  - 논리적 에러를 찾기 위한 테스트도 중요
  - 모든 문제는 Google + stack overflow로 해결 가능

### (Python 2-4강) String and advanced function concept

- 문자열 (String)

  - 시퀀스 자료형으로 문자형 data를 메모리에 저장
  - 영문자 한 글자는 1byte의 메모리 공간을 사용

- 프로그램 언어에서 데이터 타입

  - 각 타입 별로 메모리 공간을 할당 받은 크기가 다름

    | **종류** | **타입** | **크기** | **표현 범위 (32bit)** |
    | :------: | :------: | :------: | :-------------------: |
    |  정수형  |   int    |  4byte   |    -2^31 ~ 2^31-1     |
    |  정수형  |   long   |  무제한  |        무제한         |
    |  실수형  |  float   |  8byte   |  약 10^-308 ~ 10^308  |

  - 메모리 공간에 따라 표현할 수 있는 숫자 범위가 다름

  - 데이터 타입은 메모리의 효율적 활용을 위해 매우 중요

- 문자열 특징

  - 인덱싱
  - 슬라이싱
  - 덧셈과 뺄셈 연산 가능. in 명령으로 포함여부 검사 가능

- 문자열 함수

  |     **함수명**      |                   **기능**                    |
  | :-----------------: | :-------------------------------------------: |
  |       len(a)        |           문자열의 문자 개수를 반환           |
  |      a.upper()      |                 대문자로 변환                 |
  |      a.lower()      |                 소문자로 변환                 |
  |   a.capitalize()    |            첫 문자를 대문자로 변환            |
  |     a.titile()      | 제목형태로 변환, 띄워쓰기 후 첫 글자만 대문자 |
  |   a.count('abc')    |      문자열 a에 'abc'가 들어간 횟수 반환      |
  |    a.find('abc')    |  문자열 a에 'abc'가 들어간 위치(오프셋) 반환  |
  |   a.rfind('abc')    |  문자열 a에 'abc'가 들어간 위치(오프셋) 반환  |
  | a.startswith('ab'c) |  문자열 a는 'abc'로 시작하는 문자열여부 반환  |
  |  a.endswith('abc')  |   문자열 a는 'abc'로 끝나는 문자열여부 반환   |
  |      a.strip()      |               좌우 공백을 없앰                |
  |     a.rstrip()      |              오른쪽 공백을 없앰               |
  |     a.lstrip()      |               왼쪽 공백을 없앰                |
  |      a.split()      |      공백을 기준으로 나눠 리스트로 반환       |
  |   a.split('abc')    |       abc를 기준으로 나눠 리스트로 반환       |
  |     a.isdigit()     |          문자열이 숫자인지 여부 반환          |
  |     a.islower()     |         문자열이 소문자인지 여부 반환         |
  |     a.isupper()     |         문자열이 대문자인지 여부 반환         |

- 특수 문자 

  - 문자열을 표시할 때, 백슬래시 \를 사용하여 키보드로 표시하기 어려운 문자들을 표현함

    | **문자** |        **설명**         |
    | :------: | :---------------------: |
    |    \     | 다음 줄과 연속임을 표현 |
    |    \\    |       \ 문자 자체       |
    |    `     |         ' 문자          |
    |    \"    |         " 문자          |
    |    \b    |       백 스페이스       |
    |    \n    |        줄 바꾸기        |
    |    \t    |         TAB 키          |
    |    \e    |         ESC 키          |

- raw string

  - 특수문자 특수 기호인 \ escape 글자를 무시하고 그대로 출력함

- 함수 호출 방식

  - 함수에서 parameter를 전달하는 방식
    1) 값에 의한 호출 (Call by Value)
       - 함수에 인자를 넘길 때 값만 넘김.  
       - 함수 내에 인자 값 변경 시, 호출자에게 영향을 주지 않음.
    2) 참조의 의한 호출 (Call by Reference) 
       - 함수에 인자를 넘길 때 메모리 주소를 넘김. 
       - 함수 내에 인자 값 변경시, 호출자의 값도 변경됨.
    3) 객체 참조에 의한 호출 (Call by Object Reference)
       - 전달된 객체를 참조하여 변경 시 호출자에게 영향을 주나, 새로운 객체를 만들 경우 호출자에게 영향을 주지 않음.

- swap

  - 함수를 통해 변수 간의 값을 교환(Swap)하는 함수

- 변수의 범위 (Scoping Rule)

  - 지역변수 (local variable) : 함수내에서만 사용
  - 전역변수 (Global variable) : 프로그램 전체에서 사용
    - 함수 내에 전역 변수와 같은 이름의 변수를 선언하면 새로운 지역 변수가 생김
    - 함수 내에서 전역변수 사용 시 global 키워드 사용

- 재귀함수 (recursive Function)

  - 자기자신을 호출하는 함수
  - 점화식과 같은 재귀적 수학 모형을 표현할 때 사용
  - 재귀 종료 조건 존재, 종료 조건까지 함수 호출 반복

- function type hints

  - 파이썬의 가장 큰 특징 : dynamic typing

  - 처음 함수를 사용하는 사용자가 interface를 알기 어렵다는 단점이 있음

  - Type hints의 장점

    1. 사용자에게 인터페이스를 명확히 알려줄 수 있다.

    2. 함수의 문서화시 parameter에 대한 정보를 명확히 알 수 있다.

    3. mypy 또는 IDE, linter 등을 통해 코드의 발생 가능한 오류를 사전에 확인할 수 있다.
    4. 시스템 전체적인 안정성을 확보할 수 있다.

- funcino docstring

  - 파이썬 함수에 대한 상세스펙을 사전에 작성 함으로써 함수 사용자의 이행도가 오른다.
  - 세개의 따옴표로 docstring 영역 표시(함수명 아래)

- 함수 작성 가이드 라인

  - 함수는 가능하면 짧게 작성할 것 (줄 수를 줄일 것)
  - 함수의 이름에 함수의 역할, 의도가 명확히 들어날 것
  - 하나의 함수에는 유사한 역할을 하는 코드만 포함할 것
  - 인자로 받은 값 자체를 바꾸진 말 것 (임시변수 선언)

- 함수는 언제 만드는가?

  - 공통적으로 사용되는 코드는 함수로 변환
  - 복잡한 수식 or 조건일 경우, 식별 가능한 이름의 함수로 변환

- 파이썬 코딩 컨벤션

  - 사람의 이해를 돕기 위한 코딩 규칙
  - 명확한 규칙은 없음
  - 때로는 팀마다, 프로젝트마다 따로
  - 중요한 건 일관성!!!
  - 읽기 좋은 코드가 좋은 코드
  - 들여쓰기는 Tab or 4 Space 논쟁!
    - 일반적으로 4 Space를 권장함
    - 중요한 것은 혼합하지 않으면 됨
  - 한 줄은 최대 79자까지
  - 불필요한 공백은 피함
  - =연산자는 1칸 이상 안 띄움
  - 주석은 항상 갱신, 불필요한 주석은 삭제
  - 코드의 마지막에는 항상 한 줄 추가
  - 소문자l, 대문자O, 대문자I 금지
  - 함수명은 소문자로 구성, 필요하면 밑줄로 나눔

# 2. 퀴즈 리뷰

### (AI Math 1강) 퀴즈

1. L1 - 노름 구하기
2. L2 - 노름 구하기
3. L2 - 노름을 이용하여 두 벡터 사이의 거리 구하기 
4. 두 벡터 사이의 각도 구하기
5. 두 벡터의 내적 구하기

### (AI Math 2강) 퀴즈

1. 전치행렬 고르기
2. 두 행렬의 곱셈은 각 행렬의 모양과 상관없이 가능하지 않다.
3. 어떠한 행렬의 역행렬은 항상 계산할 수 없다.
4. 역행렬 고르기
5. 무어-펜로즈 역행렬 고르기

### (AI Math 3~4강) 퀴즈

1. 편미분 계산하기
2. 미분이 가능한 함수  *f* 에 대해, 주어진 점  (*x*,*f*(*x*)) 에서의 접선의 기울기가 음수라면,  *x* 를 증가시키면 함수값  *f*(*x*) 이 감소한다.
3. 함수의 극소값의 위치를 구할 때 사용하는 방법 - 경사하강법
4. 경사하강법을 사용하여 구한 함수의 극소값의 위치는 해당 함수의 최소값의 위치가 아닐 수 있다.
5. 그래디언트 벡터 고르기

# 3. 과제 리뷰

### [기본 과제 2] Text Processing 1

- 문자열을 다루는 문제입니다. 주어진 규칙을 따라 해결했습니다.

### [기본 과제 3] Text Processing 2

- 문자열을 다루는 문제입니다. 주어진 규칙을 따라 해결했습니다.

# 4. 피어세션 정리

- 강의 리뷰 및 Q&A
  - (AI Math 1강) 벡터가 뭐에요?
  - (AI Math 2강) 행렬이 뭐에요?
  - (AI Math 3강) 경사하강법 - 순한맛
  - (AI Math 4강) 경사하강법 - 매운맛
- 피어세션이 피었습니다 준비

# 5. 회고

- 강의량이 많이 경사하강법을 제대로 이해하지 못했습니다. 주말을 통해 복습을 하겠습니다. 내일도 화이팅!
