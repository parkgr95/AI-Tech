# 0311 (Day 35)

# 강의 정리

## ****(06-1강) CNN Visualization****

### 1. Visualizing CNN

### 1.1 What is CNN visualization?

- CNN 기반의 neural network는 단순히 학습 가능한 convolution과 nonlinear한 activation function들의 stack으로 이루어진 연산기
- 굉장히 좋은 성능을 보여주기도 함
- 어떤 원리로 잘 작동하는 걸까?
- 학습을 함으로써 잘되는 거 아닐까란 가설
- 학습을 통해서 convolution filter들은 어떤 것들을 배우는 걸까
- CNN의 구성에서 task의 dataset으로 입력과 출력을 줬음에도 학습이 잘 되지 않는 경우도 있다. 성능이 잘 안나오기도. 왜 안나오는 지 알아보는 걸 배워보자
- CNN은 입력을 넣으면 출력이 나오는 기계
- CNN은 여러 단계의 학습을 통해서 정해진 weight들의 조합으로 매우 복잡함. 그래서 사실상 Black box 시스템이라 할만큼 해석이 안됨
- 이런 상황에서 CNN을 visualization 함으로써 Black box를 들여다보자
1. CNN을 들여다볼 수 있는 방법
2. 왜 성능이 잘 나오는지 가늠하는 방법
3. 성능을 높일 수 있는 힌트를 얻는 방법
- 이런 CNN을 visualization 한다는 건, debugging tools를 갖는다는 것과 동일
- Example ZFNet
    - deconvolution을 이용해 visualization 시도
    - 낮은 레이어에선  방향성이 있는 선을 찾는 필터, 동그란 블럭을 찾는 기본적인 영상 처리 필터 등이 분포
    - 중간 레이어에서 높은 레이어로 갈 수 록 의미가 있는 표현을 학습

### 1.2 Vanilla example: filter visualization

- 가장 간단한 시각화 - 필터를 시각화
- Filter visualization (1st Input image conv. layer) - color edge detector, block detector 등 기본적인 영상처리필터등이 학습됨을 확인
- Activation visualization (1st conv. layer) - 한 채널이라 흑백으로 표시됨, 각 필터의 특성마다 처리된 이미지
- 첫 번째 layer를 통해 CNN의 행동을 이해할 수 있었음. 두 번째는?
    - 뒤쪽 layer는 차원 수가 높아 이미지를 직관적인 형태로 시각화할 수 없음. 사람이 해석할 수 없음
    - 또한 ,앞쪽 layer와 추상적인 합성물로 역할이 결정되기 때문에 단독으로 시각화 하는 의미가 없다.
    - 복잡한 방법이 필요

### 1.3 How to visualize neural network

- 모델 자체의 특성을 연구하는 데 방점을 둔 방법들과
- 하나의 입력 데이터부터 모델이 어떤 결론을 내었을 때 왜 그런 결론을 냈는 지 출력을 분석하는 방법론으로 분류
- 왼쪽으로 갈수록 모델을 이해하는데 초점,  오른쪽으로 갈수록 데이터를 이해하는데 초점
- 가운데를 방법들을 보자

### 2. Analysis of model behaviors

### 2.1 Embedding feature analysis

- 높은 레이어를 거친 feature 살펴보기

### 2.1 Embedding feature analysis 1

- Ex) Nearest neighbors (NN)
    - DB에 분석을 위한 예제 데이터셋을 저장
    - 오른쪽이 DB에 저장된 샘플들
    - 질의 데이터가 들어오게 되면 유사한 data를 DB에서 검색
    - feature space를 통해 확인할 수 있는 것
        1. 의미적으로 유사한 컨셉들이 clustered 되있다는 점
        2. 단순히 픽셀별로 비교. 비슷하지 않은 이미지들도 포함됨
    - 이를 통해 학습된 feature가 물체의 위치 변화에 강인하게, 대신에 컨셉을 잘 학습했다를 알 수 있다.
- 동작하는 방법
    - DB에서 뽑아 모델을 거친 feature들이 고차원의 feature space에 위치
    - 이런 feature들을 db에 저장 원래 영상과 associate 돼있음
    - query의 feature와 가까운 feature을 찾고 이 feature의 영상들을 return
- 검색된 예제를 찾아서 분석하는 방법은 전체적인 그림을 찾기 어려움

### 2.1 Embedding feature analysis 2

- 차원축소를 통해 직관적인 분포를 얻는 방법
- 차원 축소의 방법 중 하나 : t-SNE
    - [https://lovit.github.io/nlp/representation/2018/09/28/tsne/](https://lovit.github.io/nlp/representation/2018/09/28/tsne/)
    - MNIST의 feature을 2차원으로 mapping
    - 전반적으로 같은 class 끼리 잘 분포
    - 잘 학습을 했음을 알 수 있다
    - class 간의 분포를 보면, 3, 5, 8의 분포는 맞닿아있다. 경계에서 헷갈릴 수 있다. 모델은 이들을 유사하게 보고있음을 알 수 있다.

### 2.2 Activation investigation 1

- 중간, 높은 층을 해석하는 클래스 해석 방법
- 레이어의 activation을 분석
- conv5의 138 채널의 activation을 적당한 값의 thresholding하고 mask로 만들어서 영상에 overlay 해서 얻은 그림
    - thresholding : 바이너리 이미지를 만드는 가장 대표적인 방법. 바이너리 이미지(binary image)란 검은색과 흰색만으로 표현한 이미지를 의미한다. **스레시홀딩이란 여러 값을 어떤 임계점을 기준으로 두 가지 부류로 나누는 방법을 의미합니다.**
- 각 activation의 채널을 hidden node로 표현
- 공통적으로 얼굴을 찾는다던지, 난간을 찾는다던지를 통해 각 레이어의 히든 노드들의 역할을 알 수 있다.
    - Ex) 이 채널은 얼굴을 찾는 히든 노드
- 이를 통해 CNN은 여러 detection을 다층으로 쌓아, 그것들의 조합을 통해 물체를 인식한다를 알 수 있다.

### 2.2 Activation investigation 2

- 패치를 뜯어서 판단하는 방법 - Maximally activating patches
    - 각 히든 노드에서 가장 높은 값을 갖는 위치의 주변 패치를 뜯어서 나열
    - 각 히든 노드의 역할을 알 수 있다.
    - 국부적인 패치를 확인하는 중간 레이어를 분석하는 데 적합
    1. 분석하고자 하는 특정 레이어의 채널을 선택 e.g. conv. 5 layer의 14번째 채널
    2. 예제 데이터를 백본 네트워크에 넣어서 activation 값들을 뽑아내고 채널(14번째)에 activation을 저장
    3. 저장된 해당된 채널의 activation 중 가장 큰 값을 가지는 위치를 파악, 그 위치를 도출하게된 입력 도메인의 receptive field를 계산 후 field에 해당하는 입력 영상의 패치를 뜯어온다. 히든 노드별로 저장

### 2.2 Activation investigation 3

- 예제 데이터를 사용하지 않고, 네트워크 간 내제하고있는 이미지를 분석
- 예제를 통해 이 모델은 클래스를 판단하기 위해 해당 물체만이 아닌 주변의 물체도 고려하고 있음을 생각해볼 수 있다.
- 또한 학습에 사용된 데이터가 순수한 클래스들만의 데이터셋을 사용하지 않았음을 알 수 있다.
- Gradient ascent
    - 최적화를 통해 합성 영상을 찾는 과정을 거친다.
    - gradient descent와 유사하게 loss를 만들어주고 최적화를 통해 영상을 합성한다.
    - loss 디자인
        - 두 개의 loss를 합성해서 사용
            - 
                
                $$
                \underset{I}{\argmax} f(I)
                $$
                
                - I = 영상 입력
                - f = CNN
                - f(I) = CNN을 거쳐 출력된 하나의 class score. 하나의 class만 고려
                - I를 변경해서 그 score가 최대가 되게 변경
            - Reg(I) : Regularization term
                - 앞의 수식에서 나온 값이 너무 커져서 해석할 수 없을 수도 있음. 또 CNN이 이상한 이미지를 그 class로 보고 최대값으로 잡을 수 있다.
                - 이를 막고 우리가 아는 영상으로 유도하기 위해 추가
                    
                    $$
                    \lambda ||I||^2_2
                    $$
                    
                - 찾는 영상의 L2-norm
                - 람다로 작아지는 정도를 조절
    - gradient descent와 방법 유사 부호만 반대
    1. 임의의 영상(black, random initial)을 넣어줌. 그 영상의 score을 분석. 즉, 최종 결과물의 해석을 내놓는 방법
        - 임의의 영상은 회색같은 단조로운 이미지나 노이즈등 상관 없음
        - 초기 값에 따라 다양한 결과를 얻을 수 있다.
    2. backpropagate를 통해 입력값에 따라 target score가 높아지는 지 확인하고, 그 방향으로 update
    3. 입력을 현재 이미지로 update
    4. 현재 이미지로 1을 수행
    5. 이를 반복
    

### 3. Model decision explanation

# 멘토링 세션

1. [https://tootouch.notion.site/e28411e3f3804022ab666b9efe671bf3](https://www.notion.so/e28411e3f3804022ab666b9efe671bf3)
2. https://github.com/TooTouch/pytorch-tips
