# 1. 1월 27일 (Day 9) 강의 정리

### (08강) Multi-GPU 학습

- 개념정리

  - Single vs. Multi
  - GPU vs. Node (System) : 1대의 컴퓨터, GPU
  - Single Node Single GPU
  - Single Node Multi GPU
  - Multi Node Multi GPU

- Model parallel vs Data parallel

  - 다중 GPU에 학습을 분산하는 두 가지 방법
    - 모델을 나누기 : 모델 자체를 나눠 병렬적으로 돌리기
    - 데이터를 나누기 : 데이터 자체를 나눠 각각 배치를 돌려 각각의 미분값의 평균을 가지고 전체 미분값 구하기

  - 모델을 나누는 것은 생각보다 예전부터 썼음 (alexnet)
  - 모델의 병목, 파이프라인의 어려움 등으로 인해 모델 병렬화는 고난이도 과제

- Model parallel

  - 파이프라인을 만들어줘야함

    ```python
    class ModelParallelResNet50(ResNet):
        def __init__(self, *args, **kwargs):
        	super(ModelParallelResNet50, self).__init__(
        		Bottleneck, [3, 4, 6, 3], num_classes=num_classes, *args, **kwargs)
            
        self.seq1 = nn.Sequential(
            self.conv1, self.bn1, self.relu, self.maxpool, self.layer1, self.layer2
        ).to('cuda:0') # 첫번째 모델을 cuda 0에 할당
        
        self.seq2 = nn.Sequential(
            self.layer3, self.layer4, self.avgpool,
        ).to('cuda:1')  # 두번째 모델을 cuda 1에 할당
        
        self.fc.to('cuda:1')
        
    def forward(self, x):
        x = self.seq2(self.seq1(x).to('cuda:1')) # 두 모델 연결
        return self.fc(x.view(x.size(0), -1))
    ```


- Data parallel

  - 데이터를 나눠 GPU에 할당후 결과의 평균을 취하는 방법

  - minibatch 수식과 유사한데 한번에 여러 GPU에서 수행

    ​	![image-20220127113019088](https://user-images.githubusercontent.com/62732145/151379675-6e54c0a9-f36d-47ce-8fd0-7f225c4fcfaf.png)

  - PyTorch에서는 아래 두 가지 방식을 제공

    - DataParallel : 단순히 데이터를 분배한후 평균을 취함 → GPU 사용 불균형 문제 발생, Batch 사이즈 감소 (한 GPU가 병목), GIL(Global Interpreter Lock)

      - GIL : 파이썬 인터프리터가 한 스레드에 모든 자원을 허락하고 실행 시킬 수 있도록 해주는 Lock

      ```python
      parallel_model = torch.nn.DataParallel(model) # Encapsulate the model
      
      predictions = parallel_model(inputs) # Forward pass on multi-GPUs
      loss = loss_function(predictions, labels) # Compute loss function
      loss.mean().backward() # Average GPU-losses + backward pass
      optimizer.step() # Optimizer step
      predictions = parallel_model(inputs) # Forward pass with new parameters
      
      ```

      

    - DistributedDataParallel : 각 CPU마다 process 생성하여 개별 GPU에 할당 → 기본적으로 DataParallel로 하나 개별적으로 연산의 평균을 냄

      ```python
      train_sampler = torch.utils.data.distributed.DistributedSampler(train_data)
      shuffle = False
      pin_memory = True
      
      trainloader = torch.utils.data.DataLoader(train_data,
                                                batch_size=20,
                                                shuffle=True,
                                                pin_memory=True, # 연산이 빠르게 될 수 있도록 메모리에 데이터를 저장하는 방식
                                                num_workers=3, 
                                                shuffle=shuffle, 
                                                sampler=train_sampler)
          
      def main_worker(gpu, n_gpus):
          image_size = 224
          batch_size = 512
          num_worker = 8
          epochs = ...
          
          batch_size = int(batch_size / n_gpus)
          num_worker = int(num_worker / n_gpus)
          
          torch.distributed.init_process_group(
              backend='nccl',
              init_method='tcp://127.0.0.1:2568', # 멀티프로세싱 통신 규약 정의
              world_size=n_gpus,
              rank=gpu)
          
          model = MODEL
          
          torch.cuda.set_device(gpu)
          model = model.cuda(gpu)
          model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[gpu])
          
      def main():
      	n_gpus = torch.cuda.device_count()
      	torch.multiprocessing.spawn(main_worker, nprocs=n_gpus, args=(n_gpus, ))
      ```

### (09강) Hyperparameter Tuning

- 모델 accuracy에 관여하는 대표적 3가지 요소

  1. Model
     - 좋은 성능의 모델을 적용
     - 모두가 알고있기에 성능에 가장 영향을 끼치지만, 중요하지는 않다.
  2. Data
     - 새로운 데이터를 추가, 기존의 데이터 오류 검증
     - 좋은 성능에 가장 영향을 많이 끼치는 요소. 제일 중요!
     - 데이터가 많을수록 성능이 좋다.
  3. Hyperparameter
     - 데이터가 너무 큰 시대라, 의미가 없음.

- Hyperparameter Tuning

  - 모델 스스로 학습하지 않는 값은 사람이 지정 (learning rate, 모델의 크기, optimizer 등)
  - 하이퍼 파라메터에 의해서 값의 크게 좌우 될 때도 있음 (요즘은 그닥?)
  - 마지막 0.01을 쥐어짜야 할 때 도전해볼만!
  - 가장 기본적인 방법
    - grid : lr - 0.1, 0.01, 0.001, batchsize 32, 64, 128 등, 일정한 범위로 값을 잘라 차례대로 학습을 수행 
    - random : 임의의 값들을 찾는 방법.
    - random으로 수행한 뒤 값이 좋은 구간을 찾아 gird를 수행하는 방법이 좋다.
  - 최근에는 베이지안 (BOHB) 기반 기법들이 주도

- Ray

  - ML/DL의 병렬 처리를 위해 개발된 모듈

  - multi-node multi processing 지원 모듈

  - 기본적으로 현재의 분산병렬 ML/DL 모듈의 표준

  - Hyperparameter Search를 위한 다양한 모듈 제공

    ```python
    data_dir = os.path.abspath("./data")
    load_data(data_dir)
    config = { # confing에 search space 지정. 중요!
        "l1": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
        "l2": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }
    scheduler = ASHAScheduler( # 학습 스케줄링 알고리즘 지정
        metric="loss", mode="min", max_t=max_num_epochs, grace_period=1, reduction_factor=2)
    reporter = CLIReporter(metric_columns=["loss", "accuracy", "training_iteration"]) # 결과 출력 양식 지정
    
    result = tune.run( # 병렬 처리 양식으로 학습 시행
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
        config=config, num_samples=num_samples,
        scheduler=scheduler,
        progress_reporter=reporter)
    ```

### (10강) PyTorch Troubleshooting

- OOM이 해결하기 어려운 이유들…

  - 왜 발생했는지 알기 어려움
  - 어디서 발생했는지 알기 어려움
  - Error backtracking 이 이상한데로 감
  - 메모리의 이전상황의 파악이 어려움

- 가장 좋은 방법

  - Batch Size ↓ → GPU clean → Run
  - 그 외에 발생할 수 있는 문제들…

- GPUUtil 사용하기

  - nvidia-smi 처럼 GPU의 상태를 보여주는 모듈

    - iter 돌아가며 쌓이는 메모리는 확인할 수 없다.

  - Colab은 환경에서 GPU 상태 보여주기 편함

  - iter마다 메모리가 늘어나는지 확인!!

    ```python
    # in Colab
    !pip install GPUtil
    
    import GPUtil
    GPUtil.showUtilization()
    ```

    \------------------

    \| 0 | 2% | 6% |

    \| 1 | 0% | 90% |

    \| ID | GPU | MEM |

    \------------------

# 2. 퀴즈 리뷰

### [퀴즈] 

1.  

# 3. 멘토링

- 설문조사

  1. 강의 난이도

  2. 과제의 난이도

  3. 피어세션, 스페셜피어세션을 해본 소감

  4. 그 외 건의사항

- 개발자의 공유문화 소개
  - 주소 : 
  - 오픈소스
    - Github, Gitlab 등
  - PapersWithCode : github code
    - browse state-of-the-art : 이미지 모델
  - Preprint (출간되기 전 사람들에게 공개) 공유 
    - arXiv
    - Deep Learning Monitor : https://deeplearn.org/
    - Awesome -repos : ex) awesome image classification
  - 기술블로그
    - medium
    - 변성윤 마스터님 블로그 (in Slack) : 면접 질문, 호야
  - 기술유튜브
  - 기타 링크 모음 저장소
    - 오픈채팅

# 4. 피어세션 정리

# 5. 회고

