# 1. 2월 9일 (Day 15) 강의 정리

### (08강) Sequential Models - Transformer

- **Sequential Model**

  ![image-20220209221425052](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220209221425052.png)

  - 이러한 특성 때문에 sequential model은 다루기 어렵다

- **Transformer**

  - **개괄적인 수준의 설명**

    ![image-20220210101100704](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210101100704.png)

    - 재귀적 구조 x attention이라는 구조를 활용한 sequence model

    ![img](https://nlpinkorean.github.io/images/transformer/The_transformer_encoders_decoders.png)

    - nlp가 아닌 cv 등 다양한 분야에 사용 가능하다

    ![image-20220210102643639](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210102643639.png)

    - 불어에서 영어로 문장을 번역하고 있다 (sequence to sequence model).

      ->  '입력 sequence의 domain (불어)과 출력 sequence의 domain (영어)는 다를 수 있다'를 알 수 있다.

    - 입력의 단어의 개수 (3개), 출력의 단어의 개수(4개)가 다르다.

      ->  '입력 sequence와 출력 sequence의 단어의 수는 다를 수 있다'를 알 수 있다.

    - model이 1개다.

      -> 입력 개수에 상관없이 한 번에 encoding 할 수 있다. 단, generation 할 때는 (한 단어씩) autoregressive 한다.

    - 이해해야할 것! 1) 어떻게 n 개의 단어가 encoder에서 한 번에 처리가 되는가 2) encoder와 decoder 사이에 어떤 정보를 주고받는가 3) decoder가 어떻게 generization 할 수 있는가

    ![image-20220210102906550](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210102906550.png)

    - 1\) 어떻게 n 개의 단어가 encoder에서 한 번에 처리가 되는가?
      1. n 개의 단어 (vector)가 첫번째 Encoder에 들어감.
      2. Encoder는 Self-Attention와 Feed Forward Neural Network로 이루어진 구조
      3. Encoder를 거친 n 개의 단어가 두번째 Encoder에 들어감
      4. 반복
    - Self-Attention이 Transformer가 왜 잘되는지를 보여줌. FFNN은 MLP 구조와 비슷함

  - **벡터/텐서들을 기준으로 모델 살펴보기**

    ![img](https://nlpinkorean.github.io/images/transformer/embeddings.png)

    - 단어가 들어오면 기계가 번역할  수 있게 각 단어마다 특정 숫자의 vector로 표현

    ![image-20220210104809310](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210104809310.png)

    - ! **Self-Attention은 하나의 vector x1이 z1으로 넘어갈때, x1의 정보만 활용하는 것이 아니라 x2, x3의 정보를 활용한다**
    - 즉, n 개의 단어가 주어지면 각각의 i번째 벡터를 바꿀때 나머지 n-1개의 벡터를 고려한다. dependencies가 있다.
    - Feed Foward는 dependencies가 없이 그냥 통과

    ![img](https://nlpinkorean.github.io/images/transformer/encoder_with_tensors_2.png)

    - 두 개의 단어를 생각해보자.

      ![image-20220210105458793](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210105458793.png)

      - it이 어떤 단어에 dependent 한 지 알아야한다. 즉, 단어가 그 문장속의 단어들과 어떤 interaction이 있는 지를 이해하는 게 중요

      - Transformer의 역할 : 단어들과의 관계성을 파악해, 그 단어들을 더 잘 표현한다.

    ![image-20220210105926508](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210105926508.png)

    - Attention은 각 단어마다 3가지 vector (neural network)를 만들게 된다. Query, Key, Value

    ![image-20220210110135984](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210110135984.png)

    - 3 vector를 사용해 단어를 encoding 해준다.
    - 'Thinking'을 encoding 해준다고 생각할때

    ![image-20220210110348653](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210110348653.png)

    - Thinking이라는 x1 단어의 Score vector를 만들게 된다.

    - Score을 구할 때 x1의 Query와 나머지 vector의 Key를 구한 뒤 내적한다. 즉, 이 단어가 나머지 단어와 얼마나 관계가 있는 지, 유사도를 보고 얼마나 interaction 할 지 정하게 된다. 이것이 attention이다.

    - attention : Task를 수행할 때 어떤 특정 time step에 어떤 입력을 주의깊게 볼지 결정하는 기법

    ![image-20220210111136428](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210111136428.png)

    - 구한 score를 normalize 해준다. 너무 커지지 않게 해준다.
    - key vetcor 또는 query vector의 dimension에 dependent하여, 현재 dimension인 64의 루트를 취해준 8로 score를 나눠준다. (q와 k의 차원은 같다)
    - softmax를 취해준다.

    ![image-20220210111750817](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210111750817.png)

    - 각각의 Value vector에 이 값을 곱한다.

    - 이 weighted value vector들을 다 합하면, 이것이 현재 단어에 대한 self-attention layer의 출력이 된다. 

    - 주의할 점! 

      -> Q 벡터와 K 벡터의 차원은 같아야한다. 내적을 해야하기 때문. V 벡터는 달라도 괜찮다. Encoding 된 벡터와 V 벡터의 차원은 같다. (MHA에선 다름)

    ![image-20220210113612511](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210113612511.png)

    - X의 의미 : 2개의 단어, 각 단어마다 4차원으로 표현

    ![image-20220210113742901](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210113742901.png)

    - 파이토치에선 한두줄
    - 왜 잘되는 걸까? Transformer는 input, network가 고정되어 있어도, encoding 하려는 단어와 옆의 단어들의 값에 따라, encoding 된 값이 달라지게 된다. flexible 한 모델. 많은 걸 표현할 수 있는 모델
    - n 개의 단어를 한번에 처리해야하고, computational task가 n^2에 비례하기 때문에 length가 길어지면 처리할 수 있는 한계가 있다.

    ![img](https://nlpinkorean.github.io/images/transformer/transformer_attention_heads_qkv.png)

    - multi-headed attention : 앞의 attention을 여러번 수행. Q, K를 여러개 만든다.

    ![img](https://nlpinkorean.github.io/images/transformer/transformer_attention_heads_z.png)

    - n 개의 attention을 반복해 n 개의 encoding된 vector를 얻을 수 있다.
    - 고려해야할 점 : 입력(embedding된 vector)과 출력(encoding된 vector)의 차원을 맞춰줘야함

    ![img](https://nlpinkorean.github.io/images/transformer/transformer_attention_heads_weight_matrix_o.png)

    - 차원을 다시 줄여준다. (linear map)

      Ex) 80 (원래는 10인 vector가 8개) 차원인 encoding 된 vector 에 (80 x 10)인 행렬을 곱해줌

    ![img](https://nlpinkorean.github.io/images/transformer/transformer_multi-headed_self-attention-recap.png)

    - 실제 구현에서는 다름. (실습 참고)
      - 논문 : k 개의 head를 만들고, aggregate
      - 구현 : 하나의 dimension을 k 개로 나눔

    ![img](https://nlpinkorean.github.io/images/transformer/transformer_positional_encoding_vectors.png)

    - **positional encoding** : 입력에 특정 값 (pre-defined)을 더해줌. bias
    - 왜 필요한가? encoding은 순서에 independent함. 그렇기에 문장을 만들 때 단어의 순서는 중요하지 않음. 그렇기에 주어진 encoding에 값을 더한다.

    ![img](https://nlpinkorean.github.io/images/transformer/transformer_positional_encoding_example.png)

    - 4차원 encoding일때

    ![image-20220210115701650](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210115701650.png)

    - 각 단어에 벡터에 해당하는 값을 더해줌. 일종의 offset을 준다

    ![image-20220210115945587](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210115945587.png)

    - 각 encoder 내의 sub-layer 가 residual connection으로 연결되어 있으며, 그 후에는 layer-normalization과정을 거친다.

    ![img](https://nlpinkorean.github.io/images/transformer/transformer_resideual_layer_norm_3.png)

    - Decorder : encorder로 나온 정보를 가지고 출력.
    - 2\) encoder와 decoder 사이에 어떤 정보를 주고받는가 

    ![img](https://nlpinkorean.github.io/images/transformer/transformer_decoding_1.gif)

    - input에 있는 단어들을 decorder에 있는 출력하고자 하는 단어들에 대해서 attention map을 만드려면, inpjut의 단어들의 Key (K), Value (V) 벡터가 필요하다.

    ![img](https://nlpinkorean.github.io/images/transformer/transformer_decoding_2.gif)

    - decoder에서 만들어진 Query (Q) 벡터와 입력의 K, V 벡터를 가지고 최종적으로 출력 (autoregressive 하게, 하나씩)

    ![image-20220210131759300](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210131759300.png)

    - Masking : 학습을 위해 이전 단어들만 dependent하게 만드는 방법. 미래의 정보를 사용하지 않음

    ![image-20220210131949775](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210131949775.png)

    - Encoder-Decoder Attemtion : Encoder, Decoder 사이의 관계
    - Query는 이전 encoder로 주어진 정보로 만들고, Key, Value는 encoder의 정보를 활용하겠다.

    ![img](https://nlpinkorean.github.io/images/transformer/transformer_decoder_output_softmax.png)

    - decoder에서 나온 출력은 Linear layer 와 softmax layer를 통과하여 최종 출력 단어로 변환된다.

- **Vision Transformer**

  ![image-20220210132346730](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210132346730.png)

  - 이전 transformer은 번역에서 활용됐음
  - 이미지에서 많이 활용됨

- **DALL-E**

  ![image-20220210132444005](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210132444005.png)

  - decorder만 활용해 문장에 해당하는 이미지를 생성했다.

### (09강) Generative Models 1



- **Learning a Generative Model**

  - Suppose we are given images of dogs.

  - We want to learn a probability distribution p(x) such that

    - **Generation** : If we sample x_new ∼ p(x), x_new should look like a dog (**sampling**).

    - **Density estimation** : p(x) should be high if looks like a dog, and low otherwise (**anomaly detection**). 즉, 분류할 수 있다.

      -> Generative Models은 distribution을 근사하는 특성을 포함하고 있다.

      - Also known as, **explicit models**.
      - **Explicit model** : 확률값을 나타낼 수 있는 모델
      - **Implicit model**
      - : 단순 generation만 할 수 있는 모델 Ex) Gan

    - **Unsupervised representation learning** : We should be able to learn what these images have in common, e.g., ears, tail, etc (**feature learning**).

      -> feature learning이 generative model 인지는 잘 모르겠음 (마스터 피셜)

  - 어떻게 p(x)를 만들 것인가?

    - p(x) 는? 입력이 x일때의 값 또는 x를 sampling 할 수 있는 model

- **Basic Discrete Distributions**

  ![image-20220210233730217](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220210233730217.png)

  - **Bernoulli distribution** : 확률을 나타내는 숫자가 중요하다. Ex) p
  - **Categorical distribution**

- **Structure Through Independence**

  - What if X1, …, Xn are independent, then p(x1, …, xn) = p(x1)p(x2)⋯p(xn)
    - 말은 안되는 가정, 인접한 픽셀의 색이 모두 다르다?
  - How many possible states? 2^n
  - How many parameters to specify p(x1, …, xn)? n
    - 각각의 픽셀에 1개씩만 있으면 되니까
  - 2^n entries can be described by just n numbers! But this **independence assumption** is too strong to model useful distributions.

- **Conditional Independence**

  ![image-20220211000953049](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220211000953049.png)

  - Fully dependent하면 너무 많은 parameter가 필요하다. Fully independent하면 parameter가 줄지만, 표현할 수 있는 image가 적다. 중간이 필요하다!
  - Chain rule과 Conditional independence를 섞어 좋은 모델 만들기! -> auto regressive

  ![image-20220211001446906](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220211001446906.png)

  - parameter의 수를 생각할 필요가 없는 이유? 아무런 가정이 없기에 fully denpent한 모델과 같음을 알 수 있다.

### (10강) Generative Models 2

# 2. 퀴즈 리뷰

- [퀴즈] RNN
- [퀴즈] Generative Model

# 3. 과제 리뷰

- [기본 과제\] Multi-head Attention Assignment

# 4. 멘토링

- 시각화 알아두자

- 자기만의 코트 templet을 만들어보자. 깃허브로 돌아다니며

- 사전 질문

  - Mnist data의 경우 들어오는 data의 pixel이 정해져 있기 때문에 따로 transform을 시켜줄 필요가 없는데, 그렇다면 우리가 직접 만든 data의 input의 pixel이 전부 다르다면, 이를 각각 transform시켜주는 pre-processing 단계를 거쳐야 하나요? 그렇다면 이 pre-processing 과정에서 원본 데이터의 정보가 손실되지는 않나요?

    흔히 Parameter를 줄이는 방식(ex AlexNet -> VGGnet -> GoogleNet)으로 전에 있는 모델을 발전시켜 나가는 것 같은데(overfitting 방지나 generalization performacne를 높이기 위해), GPT-2, GPT-3와 같은 모델은 parameter가 1750억개라고 합니다. 파라미터를 늘리는 것은 어떤 효과를 불러올 수 있나요? 

    -> 학습이 많으면 역량은 높아짐. 대신 적어지면 capacity이 좋다. 즉, 무턱대고 많다면 overfitting 등이 발생하므로, 효율적으로 쌓아야하고, 그런 모델을 찾는 것이 목표이다.

  - 1x1 convolution과 같이 channel의 depth를 줄여 parameter의 수를 줄이는 과정을 진행하게 되는데, 이때 channel의 depth를 줄이면 어떤 변화가 일어나나요?

    -> 기본적으로 연산량이 줄어든다. 검색해볼 것

- Kaggle을 활용한 인공지능 공부 (for P stage)

# 5. 피어세션 정리

- 강의 리뷰 및 QnA

# 6. 회고
