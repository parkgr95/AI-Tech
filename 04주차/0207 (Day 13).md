# 1. 2월 7일 (Day 13) 강의 정리

### (01강) 딥러닝 기본 용어 설명 - Historical Review

- Key Components of DeepLearning
  - The **data** that the model can learn from
    - Data depend on the type of the problem to solve.
  - The **model** how to transform the data
    - AlexNet, GoogLeNet, ResNet ...
  - The **loss** function that quantifies the badness of the model
    - The loss function is aproxy of what we want to achieve.
  - The **algorithm** to adjust the parameters to minimize the loss
    - Dropout
    - Early stopping
    - k-fold validation
    - Weight decay
    - Batch normalization
    - MixUp
    - Ensemble
    - Bayesian Optimization

### (02강) 뉴럴 네트워크 - MLP (Multi-Layer Perceptron)

- Neural Networks

  - “Neural networks are computing systems vaguely inspired by the biological neural networks that constitute animal brains.” From Wiki

  - Neural networks are function approximators that stack affine transformations followed by nonlinear transformations.

    : linear + nonlinear(activation)

- Linear Neural Networks

  - simple example

    ​	![image-20220207181155384](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207181155384.png)

  - We compute the partial derivatives w.r.t. the optimization variables.

    ![제목 없음](C:\Users\82106\Desktop\박기련\공부\Ai-Tech\4주차\0207 (Day 13)\제목 없음.png)

  - Then, we iteratively update the optimization variables.

  - we can handle multi dimensional input and output.

    ![image-20220207181834368](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207181834368.png)

  - One way of interpreting a matrix is to regard it as a mapping between two vector spaces. 

- Beyond Linear Neural Networks

  - What if we stack more? 선형 모델을 여러 층 쌓는 건, 하나의 행렬을 쌓는 것과 다름없다.

  - We need nonlinearity.

  - Activationfunctions

    ![image-20220207182038104](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207182038104.png)

    - what's best? 문제마다 다르다

- Multi-Layer Perceptron

  - This class of architectures are often called multi-layer perceptrons.

    ![image-20220207153955691](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207153955691.png)

    - it can go deeper

  - What about the loss functions?

    - Regression Task : MSE
    - Classification Task : CE
    - Probabilistic Task : MLE

  

### (03강) Optimization

- **Optimization**

  - **Generalization** : How well the learned model will behave on unseen data.

    ![image-20220207185101357](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207185101357.png)

    - Generalization gap : 학습데이터의 Training error와 테스트데이터의 Test error의 차이

    - 일반적으로 어느 정도 시간이 지나면, 학습에 사용하지 않은 test error 성능이 오히려 떨어지게 된다.

    - Generalization의 퍼포먼스가 좋다 = 네트워크 성능이 학습 데이터와 비슷하게 나온다

    - Q. Generalization 성능을 높이면, 모델의 성능이 무조건 좋은가?

      A. 학습 데이터 성능 자체가 좋지 않으면, generalization 퍼포먼스가 좋아도 test data의 성능이 좋다고 할 수 없다. 너무 높으면 overfitting

  -  **Underfitting vs Overfitting**

    ![image-20220207185124975](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207185124975.png)

    - Underfitting : 네트워크가 지나치게 간단하거나, training을 조금만 시켜서 학습 데이터도 제대로 맞지 않는 현상

    - Overfitting : 학습 데이터에 대해서는 잘 동작하지만, test 데이터는 그렇지 않는 현상

    - training data가 학습하고자 하는 목적에서 나오는 data라고 가정하고 있을 뿐, 실제로는 overfitting이 target일 수 있기 때문에, 1차 회귀 문제를 풀기 위해서 나오는 다소 concept적인 얘기라 볼 수도 있다.

  - **Cross Validation (K-fold Validation)** : Cross-validation is a model validation technique for assessing how the model will generalize to an independent (test) dataset.

    ![image-20220207185152926](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207185152926.png)

    - **Validation set**이란 학습이 이미 **완료된** 모델을 **검증**하기위한 dataset이다.
    - 학습 데이터를 k개로 나눠 k-1개는 train data로 학습하고 1개로 validation check하는 과정을 K번 반복하는 평가 방법.

    - 데이터셋의 크기가 작은 경우 테스트셋에 대한 성능 평가의 신뢰성이 떨어진다. 이를 해결하기 위해 모든 데이터가 **최소 한 번**은 Train set으로 쓰이도록 한다. 

    - **학습시 어떤 방법으로든 test data를 사용하면 안된다**

      : neural network 학습시, 많은 hyperparameter 가 존재하는데, cross-validation으로 최적의 hyper parameter를 찾은 후 고정시키고, 학습시킬 때 all 데이터를 활용한다.

  - **Bias and Variance**

    ![image-20220207185214115](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207185214115.png)

    - underfitting, overfitting과 이어지는 개념.
    - Bias란 참 값과 추청 값들의 차이 (또는 평균간의 거리). 즉, 추정 값이 참 에 얼마나 접근했는지를 나타낸다.
    - Variance란 추정 값들의 흩어진 정도. 즉, 비슷한 입력값일때, 출력이 얼마나 일관적인지를 나타낸다. (탄착군)

    - bias가 높으면 underfitting, variance가 높으면 overfitting 가능성이 커진다

  - **Bias-Variance Tradeoff**

    ![image-20220207192806768](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207192806768.png)

    - *t* : target 값 + noise

    - *f*^ : 추정 값

    - 학습 데이터에 노이즈가 있다고 가정했을 때, 노이즈가 있는 target 데이터를 minimize하는 방법은 **bias, variance, noise 3가지**를 minimize 하는 것이다

    - bias가 높아지면 variance는 낮아질 가능성이 높다. 반대로 마찬가지. 즉, bias와 variance 둘 다 minimize하는 것은 사실상 힘들다 (bias-variance trade off).

  - **Bootstrapping** : Bootstrapping is any test or metric that uses random sampling with replacement.

    - 학습 데이터가 고정되어 있을 때, 데이터 셋 내의 데이터 분포가 고르지 않은 경우 random sampling을 통해서 학습 데이터를 늘리는 방법. 
    - Ex) 사과, 귤 Classifer를 만들 때, 사과의 데이터 1만개, 귤 데이터 100개가 있는 경우.

    - Ex) 학습 데이터 100개 중, 80개로 이루어진 5개의 모델을 만들고, 하나의 입력에 대해 각 모델이 예측하는 값의 일관성이 얼마나 일치하는지, 전체적인 모델의 uncertainty를 예측
    - overfitting을 줄이는 데 도움이 되며 이를 bagging이라 한다.

  - **Bagging vs. Boosting**

    ![image-20220207200159130](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207200159130.png)

    - **Bagging** (<u>**B**</u>ootstrapping <u>**agg**</u>regat<u>**ing**</u>)
      - Multiple models are being trained with bootstrapping.
      - Ex) Base classifiers are fitted on random subset where individual predictions are aggregated(voting or averaging).
      - 학습 데이터를 random subsampling하여 뽑아 각자 모델에 학습시키고 (boostraping), 여러 모델의 output으로 voting 또는 averaging (aggregation)하는  방법론
      - bootstrapping으로 데이터 여러 셋 만들고, 각각의 **독립적** 모델을 만들어 결과를 얻는다
      - 하나의 모델보다, subsampling을 통해 여러 모델을 만드는 것이 더 좋은 성능을 낼 때가 많다
    - **Boosting**
      - It focuses on those specific training samples that are hard to classify.
      - A strong model is built by combining weak learners in sequence where each learner learns from the mistakes of the previous weak learner.
      - 학습 데이터를 sequential하게 바라보고 순차적으로 학습한다. 한번 학습이 끝난 후 결과 (weak learner)에 따라 가중치를 부여하고, 그렇게 부여된 가중치가 다음 모델의 결과 예측에 영향을 준다. (독리적이지 않다). 그렇게 weak learners 로 Strong learner를 만든다.
      - 오답에 대해서는 높은 가중치를 부여하고, 정답에 대해서는 낮은 가중치를 부여한다. 따라서 오답을 정답으로 맞추기 위해 오답에 더 집중할 수 있게 된다. 
      - 부스팅은 배깅에 비해 error가 적다. 즉, 성능이 좋다. 하지만 속도가 느리고 오버 피팅이 될 가능성이 있다. 

- **Practical Gradient Descent Methods**

  - **Gradient Descent Methods**

    - Stochastic gradient descent : n개의 데이터 중 한번에 하나의 gradient를 구하고 update

    - Mini-batch gradient descent : batch size만큼 sample 활용해서 gradient를 구하고 update

    - Batch gradient descent : 한번에 모든 data로, 모든 gradient 평균을 구해 update
    - pytorch나 tensorflow에서 loss function을 구한 후 gradient를 계산할 때, automatic하게 미분 계산을 해주는데, 이 때 적절한 optimizer를 골라야 한다.

  - **Batch-size Matters**

    ![image-20220207200512981](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207200512981.png)

    - On Large-batch Training for Deep Learning: Generalization Gap and Sharp Minima, 2017

      - "It has been observed in practice that when using a larger batch there is a degradation in the quality of the model, as measured by its ability to generalize."

        : batch size가 작은 경우가 일반적으로 성능이 더 좋다

      - "We ... present numerical evidence that supports the view that large batch methods tend to converge to sharp minimizers of the training and testing functions. In contrast, small-batch methods consistently converge to flat minimizers ... this is due to the inherent noise in the gradient estimation."

        : sharp minimizer < flat minimizer

      - batch size를 줄일 경우, 일반적으로 generalization performance가 좋아지고, large batch size를 어떻게 활용하면 좋을지, 테크닉을 알려주는 실험적 논문

    - **Flat minimum**
      - training function에서 다소 멀어져도, testing function값과 크게 다르지 않음.
      - generalization 퍼포먼스가 좋다. train data에서 성능이 좋으면, test data에서도 어느정도 성능을 보장한다

    - **Sharp minimum**
      - generalization 퍼포먼스가 좋지 않다. training 단계에서 얻어지는 값이 test data 기준으로는 잘 동작하지 않을 수 있다.

  - **(Stochastic) Gradient Descent (SGD)** 

    ![image-20220207202305207](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207202305207.png)

    - 다른 기법에 비해 느리다.

    - 적절한 learning rate 값을 잡는것이 어렵다. 
    - 기울기 값이 이전과 동일하다면 step의 길이도 동일하게 update 된다.
    - 기울기 값이 0이되는 지점에서 update가 되지않기 때문에 global minimum이 아닌 local minima에 수렴할 수 있다.

  - **Momentum**

    ![image-20220207202426312](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207202426312.png)

    - SGD의 문제 해결을 위해 관성을 도입했다.

    - momentum은 한번 gradient가 특정 방향으로 흐르면, 다음번 gradient가 다소 다르게 흘러도 동일한 방향으로 흐르는 정보를 이어가는 방법론이다.

    - mini batch 사용시, 다음 번 batch는 동일한 방향으로 흐르지 않을 수도 있지만, 이전 batch의 정보를 활용한다.
    - at+1은 이전 이동거리와 관성계수 β (일반적으로 0.9)와 현재 gt를 합한 값으로 가중치를 update한다.

  - **Nesterov accelerated gradient**

    ![image-20220207203953016](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207203953016.png)

    ![image-20220207204016647](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207204016647.png)

    - momentum의 경우 현재 주어져 있는 parameter에서 gradient를 계산하고, 그 값으로 momentum을 accumulate 한다. 이 경우, global minimum으로 수렴하지 못하는 경우가 생길 수 있다. gradient만큼 하강시켰는데, global minimum을 지나친 값이라면 그 지나간 방향대로 흘러가기 때문이다.
    - NAG는 momentum으로 이동된 지점에서의 기울기를 활용하여 gradient를 계산하게 된다. gloabal minimum을 지나치게 되어도, 지나친 점에서 다시 gradient를 계산하기 때문에 momentum보다 빨리 gloabl minimum에 수렴하게 된다
    - 즉, 보통은 기울기 업데이트는 첫 번째로 적용되고, 그러고 나서, 모멘텀 방향으로 점프하는 것이 뒤 따른다. 하지만, NAG는 모멘텀 방향으로 먼저 점프를 하고, 이 방향을 기울기 업데이트와 함께 수정한다.

  - **Adagrad** : Adagrad adapts the learning rate, performing larger updates for infrequent and smaller updates for frequent parameters

    ![image-20220207204729196](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207204729196.png)

    - Adagrad에서는 동일 기준으로 update되던 각각의 parameter에 개별 기준을 적용하였다.

    - neural network의 parameter가 지금까지 얼마나 많이 변해왔는지를 계산한다.

    - neural network의 parameter가 많이 변한 경우, 더 적게 변화시키고, parameter가 적게 변한 경우 더 많이 변화시킨다. (Wt+1과 Gt는 반비례)
    - 즉, 지속적으로 변화하던 parameter는 최적값에 가까워졌을것이고 한 번도 변하지 않은 parameter는 더 큰 변화를 줘야한다는 것이 Adagrad의 개념이다.
    - Gt는 각 parameter가 얼마나 변했는지에 대해 sum한 값이기 때문에 Gradient의 sum of squares를 저장하고 있다. 이후 parameter update시 learning rate에 반비례로 적용되어 높은 값을 가지는 parameter에서는 상대적으로 적은 변화를 주고 반대로 적게 이동한 parameter에서는 큰 변화를 주게 된다.
    - ϵ는 zero division을 방지하는 값이다.
    - 학습이 진행되며 Gt가 무한으로 수렴하게 되면 Wt는 더이상 update되지 않는, 갈수록 변화 폭이 줄어들어 학습이 멈추는 현상이 발생한다.

  - **RMSprop** : RMSprop is an unpublished, adaptive learning rate method proposed by Geoff Hinton in his lecture.

    ![image-20220207205655652](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207205655652.png)

    - Adagrad에서 문제점을 개선하기 위해 gradient squares를 활용한 EMA에, step size (지수이동평균)를 추가한 방법론이다

  - **Adadelta** : Adadelta extends Adagrad to reduce its monotonically decreasing the learning rate by restricting the accumulation window.

    ![image-20220207205419665](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207205419665.png)

    - Gt가 무한으로 수렴할때 학습이 멈추는 현상을 방지하기 위해, EMA(Exponential Moving Average) (time window만큼의 값을 저장하고 있는 값)로 Gt를 업데이트 하는 방법론이다. 

    - gt는 모든 parameter에 대한 gradient 값을 가지고 있다. 만약 window size를 100으로 잡게 되면, 이전 100개의 gradient 정보를 가지고 있어야 한다.

  - **Adam** : Adaptive Moment Estimation (Adam) leverages both past gradients and squared gradients

    ![image-20220207210034497](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207210034497.png)

    - Adam effectively combines momentum with adaptive learning rate approach. 
    - gradient의 크기 변화에 따라, gradient squares의 크기에 따라 adaptive하게 learning rate (Stepsize)를 바꾸고, 이전 gradient 정보에 해당하는 momentum을 합하는 방법이다.
    - Adam의 hyperparameter는 1) momentum을 얼마나 잘 유지시키는지, 2) gradient square에 대한 EMA 정보, 3) learning rate, 4) 입실론 값(zero division)로 총 4개이다.

  * **정리**

    ![산내려오는작은오솔길잘찾기(Optimizer)의발달계보 SGD Momentum NAG Adagrad RMSProp AdaDelta Adam Nadam 스텝계산해서움직인후,  아까내려오던관성방향또가자 일단관성방향먼저움직이고...](https://image.slidesharecdn.com/random-170910154045/95/-49-638.jpg?cb=1505089848)

    - SGD, Momentum, Adam 등을 직접 구현하기보다, 적절히 사용하는 것을 목표로 하자

  * **SGD vs. Momentum vs Adam**

    ![image-20220207210417022](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207210417022.png)

    - Adam = adaptive learning rate + momentum,  둘다 쓰는 게 중요함을 알 수 있다. 빠른 학습 효과 가능
    - Momentum : 이전의 gradient 활용. 데이터를 한번에 많이 보는 효과
    - SGD : 이전 정보가 활용안되면?  너무 많은 iter가 필요하다. 제일 큰 peak만 잡는 이유? 많이 맞추는 곳만 집중.

- **Regularization**

  - neural network를 학습시킬 때 사용하는 일종의 도구, 학습을 방해하기 위한 방법론으로, generalization performance를 높이는 것이 목적이다. 이 때 학습을 방해한다는 의미는, 모델이 학습 데이터에서만 잘 동작하는 것이 아니라, 테스트 데이터에서도 잘 동작하도록 한다는 의미이다.

  - **Early stopping**

    ![image-20220207230131772](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207230131772.png)

    - 학습이 더 이상 개선의 여지가 없을 때 즉, loss가 어느 시점보다 커지기 시작할때 학습을 종료시킨다.

  - **Parameter norm penalty** : It adds smoothness to the function space

    ![image-20220207230455564](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207230455564.png)

    - neural network가 만들어 내는 function space에서, 최대한 부드러운 functino이 generalization performance를 높인다는 개념.

    - 비용함수에 제곱을 더하거나(L2) 절댓값을 더해서(L1) 웨이트의 크기에 제한을 준다.

    - 네트워크의 parameter squre값의 합을 줄이고, 학습시 W가 작으면 작을수록 좋다.

  - **Data augmentation**

    ![image-20220207231109527](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207231109527.png)

    - More data are always welcomed

      만약 데이터 수가 무한히 많다면, 모델의 성능은 웬만하면 매우 좋을 것이다.

    - However, in most cases, training data are given in advance.

      하지만 데이터의 수가 충분하지 않다면, 아무리 딥러닝을 잘 해도 모델의 성능이 좋지 않을 가능성이 높아, 기존 ML에서 사용하던 방법론의 performance가 더 좋아진다.

    - In such cases, we need data augmentation.

      이 때, data augumentation이 필요해진다.

      ![image-20220207231327235](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207231327235.png)

    - 이미지 데이터의 경우, 회전, 대칭 등으로 데이터를 늘일 수 있다. 단 변화를 해도 이미지 label이 바뀌지 않는 한도 내에서 변화시켜야 한다.

  - **Noise robustness** : Add random noises inputs or weights.

    ![image-20220207231445399](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207231445399.png)

    - 머신러닝에서 일반화(generalization)는 일부 특정 데이터만 잘 설명하는(=overfitting) 것이 아니라 범용적인 데이터도 적합한 모델을 의미한다. 즉, 잘 일반화하기 위해서는 이상치나 노이즈가 들어와도 크게 흔들리지 않아야(=robust) 한다.

    - data augumentation과의 차이점은 입력 데이터뿐 아니라 neural network에도 noise를 추가하는 방법이다. 성능이 높아지는 이유에 대해서는 아직 의문점이 많다.
    - 레이어 중간에 노이즈를 추가(noise injection)하는 게 파라미터를 줄이는 것(L2 weight decay)보다 강력할 수 있다. 

  - **Label smoothing**

    ![image-20220207231708235](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207231708235.png)

    - **Mix-up** : constructs augmented training examples by mixing both input and output of two randomly selected training data.

      data augumentation과 비슷한 방법론으로, 2개의 random 데이터를 뽑고, 섞어 성능을 높인다.

    - **CutMix** : constructs augmented training examples by mixing inputs with cut and paste and outputs with soft labels of two randomly selected training data.

    - 분류문제에서, 내 image가 있는 공간 속 decision 바운더리를 찾아서, 해당 바운더리로 두 class 분류를 잘 되게 하는것이 목적이다

    ![image-20220207231950783](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207231950783.png)

    - 정리 :
      - Mix-up : 두 이미지를 골라 blending하게 섞고, label 또한 mix한다
      - cutout : 일정 영역을 제외한다
      - CutMix : 특정 영역을 기준으로 이미지를 혼합한다.

  - **Dropout** : In each forward pass, randomly set some neurons to zero.

    ![image-20220207232314011](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207232314011.png)

    - neural network의 일부 뉴런 W값을 0으로 바꾸는 것.

    - 만약 dropout ratio = 0.5라면, 레이아웃마다 뉴런의 50% 가중치를 0으로 바꾼다

  - **Batch normalization **: Batch normalization compute the empirical mean and variance independently for each dimension (layers) and normalize.

    ![image-20220207232405439](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220207232405439.png)

    - 각 layer에 대해 평균과 분산을 독립적으로 계산하고 정규화하는 방법론이다.
    - **배치 정규화는 평균과 분산을 조정하는 과정이 별도의 과정으로 떼어진 것이 아니라, 신경망 안에 포함되어 학습 시 평균과 분산을 조정하는 과정** 역시 같이 조절된다
    - 즉, 학습하는 과정 자체를 전체적으로 안정화하여 학습 속도를 가속 시킬 수 있는 근본적인 방법

# 2. 퀴즈 리뷰 #

### [퀴즈] 딥러닝 기본

### [퀴즈] 최적화

# 3. 과제 리뷰

### [기본 과제\] MLP Assignment

### [기본 과제\] Optimization Assignment

# 4. 피어세션 정리

- 강의 리뷰 및 QnA
  - 딥러닝 기본
  - 최적화

# 5. 회고

최적화, 정규화를 확실히 알아둘것! 어떻게 쓰는 것 보다는 어떨때 써야하는 지를 알아두자!
