# 1. 2월 21일 (Day 23) 강의 정리

### (1강) Competition with AI Stages!

- Problem Definition (문제 정의)

  - 내가 지금 풀어야 할 문제가 무엇인가?

  - 이 문제의 Input과 Output은 무엇인가?!
  - 이 솔루션은 어디서 어떻게 사용되어지는가?
  - ...

- Data Description
  - File 형태와 Metadata Field 소개 및 설명 - "데이터 스펙 요약본"

- Notebook
  - 데이터 분석, 모델 학습, 테스트 셋 추론의 과정을 서버에서 연습 가능하다.

- Submission & Leaderboard
  - 테스트 예측 결과물 제출 & 순위 확인

- Discussion
  - 등수를 올리는 것보다 문제를 해결하고 싶은 마음

- Machine Learning Pipeline
  - Domain Understanding (Overview 페이지에서 습득 가능) -> Data Mining (Competition의 경우는 x) -> Data Analysis -> Data processing -> Modeling -> Training -> Deploy (Competition의 경우는 x)

### (2강) Image Classification & EDA

- EDA (Exploratory Data Analysis)
  - 탐색적 데이터 분석
  - 데이터를 이해하기 위한 노력

- Image Classification

  - Image : "시각적 인식을 표현한 인공물(Artifact)"

  - Model
    - Input + Model = Output

  - Image Classification Model
    - Image + Classification Model = Class

### (3강) Dataset

- Pre-processing

  - Bounding box

    - 가끔 필요 이상으로 많은 정보를 가지고 있기도 한다. (이번 것은 bounding box가 없지만 마스크가 중간에 있는 것을 생각해볼 수 있다.)

  - Resize

    - 큰 사이즈의 경우, 학습을 하는데 많은 시간이 소요될 수 있다.

      -> 효율적인 size를 찾는 것이 중요하다!!!

      Ex) 이미지를 밝기를 조절하는 것도 좋을 수 있다.

- Generalization

  - Bias & Variance

    - Variance가 높으면 Overfitting이 일어나고 Bias가 높으면 Underfitting이 일어난다.

  - Train / Validation

    - 훈련 셋 중 일정 부분을 따로 분리, 검징 셋으로 활용한다.

  - Data Augmentation

    - 주어진 데이터가 가질 수 있는 경우, 상태의 다양성이 존재한다. (데이터 다양화 시키기!)

      -> 밝기 조절, 회전 등 여러 noise로 좀 더 다양한 이미지를 훈련시킨다.

      -> 모델의 쓰임새를 살펴보자!!

  - torchvision.transforms

  - Albumentations

    - 좀 더 빠르고 다양한 것을 제공한다. (transforms보다)

      -> 이 라이브러리를 이번 마스크 대회에 1번 사용해보자!!

### (4강) Data Generation

- **Data Feeding**

  - Feed: 먹이를 주다 = 대상의 상태를 고려해서 적정한 양을 준다.

  - 모델에 먹이 (Data)를 주다?

    ![image-20220221144433864](C:\Users\82106\AppData\Roaming\Typora\typora-user-images\image-20220221144433864.png)

    - 설계, 제작(데이터 생성), 포장(모델)의 과정이 있다고 할 때, 어느 하나의 속도를 높인다고 해서 전반적인 속도가 반드시 향상되는 것은 아니다.
    - 다른 요소의 고정적인 속도로 인하여 예상/원한는 속도가 안나올 수 있다.
    - 그래서 Data Generator를 살펴보는 과정이 필요하다.
      - 어떤 전처리를 하느냐에 따라 만드는 속도가 다르고, 각 처리 과정의 순서에 따른 속도도 다르다.
      - Ex) resize로 사이즈를 늘린 뒤 random rotate 하는 것과 그 반대의 순서는 속도 차이가 확연하다. -> transforms를 compose 할 때는 신중하게 생각하자.
    - 최적화같은 엔지니어링적인 요소들도 알고 있어야 한다.

- **torch.utils.data**

  - **Dataset**

    - Dataset 구조

      ```python
      from torch.utils.data import Dataset # torch.utils.data의 Dataset 라이브러리 상속!
      
      class Mydataset(Dataset):
        def __init__(self): # MyDataset 클래스가 처음 선언 되었을 때 호출
            pass
        
        def __getitem__(self, index): # MyDataset의 데이터 중 index 위치의 아이템을 리턴
           return None
        
        def __len__(self): # MyDataset 아이템의 전체 길이
           return None
      ```

    - 내 data를 pytorch의 Dataset 구조로 만드는 것

    - Dataset 클래스를 상속시켜 torch에서 사용할 수 있도록 만들어준다.

      - `__init__`
        - 데이터 위치, 절대경로같은 메타데이터
        - 저장 시에 주로 사용된다.
        - 객체를 선언하면 바로 실행된다.

      - `__getitem__`
        - file을 읽어서 뱉어주는 역할
        - 데이터를 가져오는 역할
        - 데이터를 알아서 슬라이싱/인덱싱 해준다.

    - `__len__`

    - 이들이 없으면 오류가 난다. (반드시 선언되어야함)

  - **DataLoader**

    - 내가 만든 Dataset을 효율적으로 사용할 수 있도록 관련 기능 추가

  - **Dataset과 DataLoader는 분리되는 것이 좋다!**

    - 서로 하는 일을 분리해서 정해주자!
    - 재활용(재사용) 측면에서 중요!
    - Dataset: Vailla data를 원하는 형태로 출력해주는 클래스
    - DataLoader: Dataset을 더 효율적으로 사용하기 위함
      - util적 성격
      - 효율적으로 데이터를 뽑는 데에 사용된다.
      - dataset을 다른 것으로 교체해도 문제없다.
      - 데이터셋에 따라 계속 만들 필요 없고, dataloader는 재사용 가능하다.

  - **DataLoader's Parameters**

    - **dataset** ([*Dataset*](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)) – `torch.utils.data.Dataset`의 객체를 사용

      - **Map-style dataset**
        - 일반적인 dataset type 
        - index가 존재하여 data[index]로 데이터를 참조할 수 있음
        - `__getitem__`과 `__len__` 선언 필요
      - **Iterable-style dataset**
        - random으로 읽기에 어렵거나, data에 따라 batch size가 달라지는 데이터(dynamic batch size)에 적합
        - 현재는 쓰이지 않는다.

    - **batch_size** ([*int*](https://docs.python.org/3/library/functions.html#int)*,* *optional*) – **배치(batch)**의 크기입니다

    - **shuffle** ([*bool*](https://docs.python.org/3/library/functions.html#bool)*,* *optional*) –  데이터를 DataLoader에서 섞어서 사용하겠는지를 설정. 실험 재현을 위해 `torch.manual_seed`를 고정할 수 있다.

    - **sampler** ([*Sampler*](https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler) *or* *Iterable**,* *optional*) – sampler는 index를 컨트롤하는 방법. 데이터의 index를 원하는 방식대로 조정.

      - map-style에서 컨트롤하기 위해 사용하며 `__len__`과 `__iter__`를 구현하면 됨. 그 외의 미리 선언된 Sampler는 다음과 같습니다.
        - `SequentialSampler` : 항상 같은 순서
        - `RandomSampler` : 랜덤, replacemetn 여부 선택 가능, 개수 선택 가능
        - `SubsetRandomSampler` : 랜덤 리스트, 위와 두 조건 불가능
        - `WeigthRandomSampler` : 가중치에 따른 확률
        - `BatchSampler` : batch단위로 sampling 가능
        - `DistributedSampler` : 분산처리 (`torch.nn.parallel.DistributedDataParallel`과 함께 사용)

    - **batch_sampler** ([*Sampler*](https://pytorch.org/docs/stable/data.html#torch.utils.data.Sampler) *or* *Iterable**,* *optional*) – batch 단위로 sampling할때 사용.`sampler`와 거의 동일

    - **num_workers** ([*int*](https://docs.python.org/3/library/functions.html#int)*,* *optional*) – 데이터 로딩에 사용하는 subprocess개수. (멀티프로세싱)

      - 데이터를 불러 CPU와 GPU 사이에서 많은 교류가 일어나면 오히려 병목이 생길 수 있으니 잘 조절해볼 것.

    - **collate_fn** (*callable**,* *optional*) – 데이터셋에서 sample list를 batch 단위로 바꾸기 위해 필요한 기능. zero-padding이나 Variable Size 데이터 등 데이터 사이즈를 맞추기 위해 많이 사용합니다.

    - **pin_memory** ([*bool*](https://docs.python.org/3/library/functions.html#bool)*,* *optional*) – `True`로 선언하면, 데이터로더는 Tensor를 CUDA 고정 메모리에 올립니다.

    - **drop_last** ([*bool*](https://docs.python.org/3/library/functions.html#bool)*,* *optional*) – 마지막 batch를 사용하지 않게 한다.

    - **timeout** (*numeric**,* *optional*) – 양수로 주어지는 경우, DataLoader가 data를 불러오는데 제한시간입니다.

    - **worker_init_fn** (*callable**,* *optional*) – num_worker가 여러 개라면, 이 파라미터는 어떤 worker를 불러올 것인가를 리스트로 전달.

    - **persistent_workers** ([*bool*](https://docs.python.org/3/library/functions.html#bool)*,* *optional*) – 백그라운드 실행

    - Reference

      - [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)

      - [Hello Subinium!](https://subinium.github.io/)

      - [Hulk의 개인 공부용 블로그](https://hulk89.github.io/)

### Special Mission

# 2. 피어세션 정리

- 강의 리뷰 및 QnA
  - (1강) Competition with AI Stages!
  - (2강) Image Classification & EDA
  - (3강) Dataset
  - (4강) Data Generation

# 3. 회고
